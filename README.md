With the rapid advancement of generative models, deepfake audio has become a significant cybersecurity threat, enabling the creation of highly realistic yet fabricated voice recordings used for scams, misinformation, and identity theft. Unlike visual deepfakes, synthetic speech is harder to detect due to its subtle features, making manual identification unreliable and time-consuming. This project aims to train Logistic Regression, XGBoost, SVM, CNN and TCN for deepfake audio detection system by extracting key features, optimizing these algorithms, and evaluating their performance. Our results show that XGBoost performs well for cqtspec feature whereas SVM works best with logspec and TCN achieves the best results using melspec features for detecting deep fake audio recordings. A reliable detection system is essential for safeguarding personal identities, preventing financial fraud, and ensuring trust in digital communications, with broad implications for cyber-security, law enforcement, and media verification. 
